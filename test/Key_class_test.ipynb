{
 "cells": [
  {
   "cell_type": "raw",
   "id": "be372c2b-3e2b-43d9-910f-3742670aafec",
   "metadata": {},
   "source": [
    "Class takes an input csv file or pandas Dataframe file for a final pd.DataFrame format. The and save each row and column as something to be called on per well to rearrange image input information to save the tiff when calling a specific function.\n",
    "\n",
    "output: date-info_construct-info_experiment-info_ + ... columns x - info x... + well-info+replicatenumber\n",
    "\n",
    "example file'D:\\\\olympus_images\\\\test\\\\test\\\\\\\\20250124_102049_test-10-1-10-1_PK-DirectA_Image_A1-1.vsi'\n",
    "separator = '_' 1: Date, 2: drop in this case, 3: experiment, 4: observation (images are concatenated and observation are no longer needed) , 5: useless in this case, 6:well (important for iteration)\n",
    "\n",
    "columns: well, experiment, passage, ...\n",
    "\n",
    "should be file specific, other experiment stuff can be added in a secondary class for dataframe creation. \n",
    "save file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d2b07bf-c5e7-4cde-9273-c8b12caa15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Union\n",
    "from constants.columns_names import col_dic\n",
    "from file_handling.generic_handlers import split_filename\n",
    "\n",
    "class Key:\n",
    "    \"\"\"\n",
    "    The Key class processes key information from a pandas DataFrame, CSV file, or a list of CSV file paths.\n",
    "    It builds a mapping to generate unique save file names based on image file information and a well identifier.\n",
    "    \n",
    "    Main functionality:\n",
    "      - Loads and normalizes key data (forcing column names to lowercase).\n",
    "      - Optionally validates that all expected columns exist.\n",
    "      - Updates an internal column dictionary (col_dic) with any additional keys provided.\n",
    "      - Creates a dictionary mapping each well (from the \"well\" column) to a generated string.\n",
    "      - Generates a final filename by combining well-specific information with image-specific data.\n",
    "      \n",
    "    Usage:\n",
    "        key_instance = Key(key_input, image_file_information=['date', 'experiment', 'well'])\n",
    "        final_filename = key_instance.current_filename_save_parameters(image_file, well)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 key: Union[pd.DataFrame, str, List[str]], \n",
    "                 image_file_information: List[str], \n",
    "                 add_dic_key: Union[str, List[str]] = None,\n",
    "                 skip_validation: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the Key class.\n",
    "        \n",
    "        Parameters:\n",
    "            key: Input key data (DataFrame, CSV file path, or list of CSV file paths).\n",
    "            image_file_information: List of image file information fields to parse.\n",
    "            add_dic_key: Optional additional keys to add to the internal column dictionary.\n",
    "            skip_validation: If True, skip validation of column names.\n",
    "        \"\"\"\n",
    "        # Load key data from a DataFrame, CSV file, or list of CSV file paths.\n",
    "        if isinstance(key, pd.DataFrame):\n",
    "            self.key = key.copy()\n",
    "            self.key.columns = self.column_lower()\n",
    "        elif isinstance(key, str):\n",
    "            try:\n",
    "                self.key = pd.read_csv(key)\n",
    "                self.key.columns = self.column_lower()\n",
    "            except Exception as e:\n",
    "                raise ValueError(\"Expected a valid file path for key.\") from e\n",
    "        elif isinstance(key, list):\n",
    "            try:\n",
    "                key_dfs = []\n",
    "                for file_path in key:\n",
    "                    tmp = pd.read_csv(file_path)\n",
    "                    key_dfs.append(tmp)\n",
    "                self.key = pd.concat(key_dfs, ignore_index=True)\n",
    "                self.key.columns = self.column_lower()\n",
    "            except Exception as e:\n",
    "                raise ValueError(\"Expected a list of file path strings for key.\") from e\n",
    "        else:\n",
    "            raise ValueError(\"Key must be a DataFrame, a file path string, or a list of file paths.\")\n",
    "        \n",
    "        # Create a copy of the column dictionary to avoid mutating the imported dictionary.\n",
    "        self.col_dic = col_dic.copy()\n",
    "        if add_dic_key is not None:\n",
    "            if isinstance(add_dic_key, str):\n",
    "                self.col_dic[add_dic_key.lower()] = add_dic_key.lower()\n",
    "            elif isinstance(add_dic_key, list):\n",
    "                new_dic = {col.lower(): col.lower() for col in add_dic_key}\n",
    "                self.col_dic.update(new_dic)\n",
    "        \n",
    "        # Optionally validate the columns.\n",
    "        self.skip_validation = skip_validation\n",
    "        if not self.skip_validation:\n",
    "            self.validate_column_name()\n",
    "        \n",
    "        # Build a dictionary mapping wells to generated file name strings.\n",
    "        self.save_image_dic = self._make_file_name_from_key(self.key)\n",
    "        # Store the image file information used for constructing image-specific save parameters.\n",
    "        self.image_file_information = image_file_information\n",
    "\n",
    "    def column_lower(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Convert the DataFrame's column names to lowercase.\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: List of lowercase column names.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return [col.lower() for col in self.key.columns]\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"Failed to convert column names to lowercase.\") from e\n",
    "\n",
    "    def _check_strings(self, columns: List[str]) -> bool:\n",
    "        \"\"\"\n",
    "        Check that every column name in the provided list exists in the internal column dictionary.\n",
    "        \n",
    "        Parameters:\n",
    "            columns (List[str]): List of column names to check.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if all columns are found.\n",
    "        \"\"\"\n",
    "        return all(string in self.col_dic for string in columns)\n",
    "        \n",
    "    def validate_column_name(self) -> bool:\n",
    "        \"\"\"\n",
    "        Validate that the key DataFrame's columns match the expected column names.\n",
    "        If any expected column is missing, a detailed error is raised.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if all expected columns are present.\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If one or more expected columns are missing.\n",
    "        \"\"\"\n",
    "        return self._check_strings(self.key.columns, self.col_dic)\n",
    "            \n",
    "    \n",
    "    \n",
    "    def _get_columns(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieve a list of column names from the key DataFrame.\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: List of column names.\n",
    "        \"\"\"\n",
    "        return list(self.key.columns)\n",
    "        \n",
    "    def _make_file_name_from_key(self, df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Create a dictionary mapping the value from the 'well' column to a generated string.\n",
    "        The string is constructed by concatenating each column name with a hyphen and the\n",
    "        corresponding cell value from the row.\n",
    "        \n",
    "        Parameters:\n",
    "            df (pd.DataFrame): The key DataFrame.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary with well values as keys and generated file name strings as values.\n",
    "        \"\"\"\n",
    "        well_col = 'well'\n",
    "        # Validate columns if not skipping.\n",
    "        if not self.skip_validation:\n",
    "            self.validate_column_name()\n",
    "        \n",
    "        result = {}\n",
    "        for idx, row in df.iterrows():\n",
    "            try:\n",
    "                key_val = row[well_col]\n",
    "                # Build a string for this row using \"column-value\" for each column.\n",
    "                value_parts = [f\"{col}-{row[col]}\" for col in df.columns]\n",
    "                value = \"_\".join(value_parts)\n",
    "                result[key_val] = value\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Error generating file name from key for row {idx}.\") from e\n",
    "        return result\n",
    "\n",
    "    def _check_well_dic(self, diction: dict, separator: str) -> dict:\n",
    "        \"\"\"\n",
    "        Split the well information into 'well' and 'tech_replicate' parts if the separator is present.\n",
    "        \n",
    "        Parameters:\n",
    "            diction (dict): Dictionary containing image file information.\n",
    "            separator (str): Character used to separate well and technical replicate.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Updated dictionary with separated 'well' and 'tech_replicate' keys.\n",
    "        \"\"\"\n",
    "        new_diction = diction.copy()\n",
    "        if \"well\" in new_diction and separator in new_diction[\"well\"]:\n",
    "            try:\n",
    "                split_ind = new_diction[\"well\"].split(separator, 1)\n",
    "                new_diction[\"well\"] = split_ind[0]\n",
    "                new_diction[\"tech_replicate\"] = split_ind[1]\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(\"Error splitting well information.\") from e\n",
    "        return new_diction\n",
    "\n",
    "    def _make_image_name_dict(self, list_names: List[str]) -> dict:\n",
    "        \"\"\"\n",
    "        Create a dictionary by pairing the pre-defined image file information with\n",
    "        the components obtained by splitting an image filename.\n",
    "        \n",
    "        Parameters:\n",
    "            list_names (List[str]): List of strings obtained from splitting an image filename.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary mapping image file info keys to their corresponding values.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            new_dic = {key: value for key, value in zip(self.image_file_information, list_names) if key is not None}\n",
    "            new_dic = self._check_well_dic(new_dic, '-')\n",
    "            return new_dic\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"Error generating image name dictionary.\") from e\n",
    "        \n",
    "    def get_image_dic(self) -> dict:\n",
    "        return self.save_image_dic\n",
    "    \n",
    "    def current_filename_save_parameters(self, image_file: str, well: str) -> str:\n",
    "        \"\"\"\n",
    "        Build the final filename for saving an image by combining pre-built well-specific\n",
    "        information with additional image-specific information extracted from the image filename.\n",
    "        \n",
    "        Parameters:\n",
    "            image_file (str): Path to the image file.\n",
    "            well (str): Well identifier used to retrieve pre-built save information.\n",
    "            \n",
    "        Returns:\n",
    "            str: Final filename string ending with '.tif'.\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If no save information is found for the provided well.\n",
    "            RuntimeError: If any error occurs during filename construction.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Parse the image file to get its components.\n",
    "            image_file_names = split_filename(image_file, '_')\n",
    "            # Build a dictionary mapping image file information.\n",
    "            image_info_dic = self._make_image_name_dict(image_file_names)\n",
    "            # Convert the dictionary to a string in the format \"key-value_key-value\".\n",
    "            image_info_str = \"_\".join([f\"{k}-{v}\" for k, v in image_info_dic.items()])\n",
    "            # Retrieve prebuilt save information for the given well.\n",
    "            current_well_information = self.save_image_dic.get(well, \"\")\n",
    "            if not current_well_information:\n",
    "                raise ValueError(f\"No save information found for well: {well}\")\n",
    "            # Construct the final filename.\n",
    "            final_filename = f\"{current_well_information}_{image_info_str}.tif\"\n",
    "            return final_filename\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"Error constructing current filename save parameters.\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bab7a1ab-d891-4bcb-9169-83bb139c9ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_class = Key(r'E:\\Patrick\\Keys\\InfectionKey.csv', ['date', 'experiment', None, None, None, 'well'], skip_validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f52fe63-9e83-41e7-a181-15f06278515a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well-A1_construct-1_experiment-Growth_replicate-1_passage-26_date-20240903_experiment-Infection_well-A1_tech_replicate-1.tif\n"
     ]
    }
   ],
   "source": [
    "print(key_class.current_filename_save_parameters('20240903_Infection_B!WT_PK-DirectA_Image_A1-1.vsi', well='A1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "338cf8d9-ad90-4b0f-88b0-130338b4b237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0      A1\n",
      "1      A2\n",
      "2      A3\n",
      "3      A4\n",
      "4      A5\n",
      "     ... \n",
      "91     H8\n",
      "92     H9\n",
      "93    H10\n",
      "94    H11\n",
      "95    H12\n",
      "Name: well, Length: 96, dtype: object, 0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "91    Bt\n",
      "92    Bt\n",
      "93    Bt\n",
      "94    Bt\n",
      "95    Bt\n",
      "Name: construct, Length: 96, dtype: object, 0        Growth\n",
      "1     Infection\n",
      "2     Infection\n",
      "3     Infection\n",
      "4     Infection\n",
      "        ...    \n",
      "91    Infection\n",
      "92    Infection\n",
      "93    Infection\n",
      "94    Infection\n",
      "95    Infection\n",
      "Name: experiment, Length: 96, dtype: object, 0     1\n",
      "1     1\n",
      "2     2\n",
      "3     3\n",
      "4     4\n",
      "     ..\n",
      "91    1\n",
      "92    2\n",
      "93    3\n",
      "94    4\n",
      "95    5\n",
      "Name: replicate, Length: 96, dtype: int64, 0     26\n",
      "1     26\n",
      "2     26\n",
      "3     26\n",
      "4     26\n",
      "      ..\n",
      "91    14\n",
      "92    14\n",
      "93    14\n",
      "94    14\n",
      "95    14\n",
      "Name: passages, Length: 96, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "print([key_class.key[index] for index in key_class.key.columns])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db3d1b95-b535-4e14-83f4-a61c0848416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = split_filename('20240903_Infection_B!WT_PK-DirectA_Image_A1-1.vsi', '_')\n",
    "dic_list = ['date', 'experiment', None, None, None, 'well']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0dc9dc6b-5749-43e6-a2bd-18bc40628ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dic = {key: value for key, value in zip(dic_list, names) if key != None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "873292af-ce84-43a2-8639-27327c00b9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '20240903', 'experiment': 'Infection', 'well': 'A1', 'tech_replicate': '1'}\n"
     ]
    }
   ],
   "source": [
    "if '-' in tmp_dic['well']:\n",
    "    split_ind = tmp_dic['well'].split('-')\n",
    "    tmp_dic['well'] = split_ind[0]\n",
    "    tmp_dic['tech_replicate'] = split_ind[1]\n",
    "print(tmp_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d678ae-3a87-4ff2-a3c2-a8fdfff26a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
